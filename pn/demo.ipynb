{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "api_key = \"sk-cRk2eMr7OMij3FKyD4C41a291c9943018728C3D479Dd1e99\"\n",
    "base_url = \"https://chatapi.onechats.top/v1/\"\n",
    "\n",
    "\n",
    "class OpenAIBackend:\n",
    "    _aclient = None\n",
    "    _client = None\n",
    "\n",
    "    @staticmethod\n",
    "    def config(**kwargs) -> None:\n",
    "        from openai import OpenAI, AsyncOpenAI\n",
    "        OpenAIBackend._client = OpenAI(**kwargs)\n",
    "        OpenAIBackend._aclient = AsyncOpenAI(**kwargs)\n",
    "\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    async def run(self, messages) -> str:\n",
    "        response = self._client.chat.completions.create(messages=messages, **self.kwargs)\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    async def arun(self, messages) -> str:\n",
    "        response = await self._aclient.chat.completions.create(messages=messages, **self.kwargs)\n",
    "        return response.choices[0].message.content\n",
    "OpenAIBackend.config(api_key=api_key,base_url=base_url)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from jinja2 import Template, Environment, FileSystemLoader\n",
    "\n",
    "class SinglePasser:\n",
    "    \"\"\"只有初始化的prompt设定，以及forward生成内容。\"\"\"\n",
    "\n",
    "    def __init__(self, backend: OpenAIBackend, prompt: Template = None, system: str = None, **kwargs):\n",
    "        self.system = system\n",
    "        self.prompt = prompt\n",
    "        self.backend = backend\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    async def forward(self, query: str):\n",
    "        messages: list[dict[str, str]] = []\n",
    "        if self.system:\n",
    "            messages.append({'role': 'system', 'content': self.system})\n",
    "        if self.prompt:\n",
    "            new_query = self.prompt.render(query=query, **self.kwargs)\n",
    "            messages.append({'role': 'users', 'content': new_query})\n",
    "\n",
    "        return await self.backend.arun(messages)\n",
    "\n",
    "class CoT(SinglePasser):\n",
    "\n",
    "    def __init__(self, backend: OpenAIBackend, prompt: Template = None, **kwargs):\n",
    "        if not prompt:\n",
    "            prompt = Environment(loader=FileSystemLoader(\".\")).get_template(\n",
    "                \"../prompt_weights/cot.j2\"\n",
    "            )\n",
    "        super().__init__(backend, prompt, **kwargs)\n",
    "\n",
    "    async def forward(self, query: str):\n",
    "        answer=await super().forward(query)\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
